# ====================================================================
#  Streamlit Cloud ç’°å¢ƒå•é¡Œã¸ã®æœ€çµ‚å¯¾ç­–ã‚³ãƒ¼ãƒ‰
# ====================================================================
import subprocess
import sys
import os
import streamlit as st

# Streamlit Cloudä¸Šã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å¼·åˆ¶ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚’å®Ÿè¡Œ
# (ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ä¸è¦ãªãŸã‚)
if "STREAMLIT_SHARING_MODE" in os.environ:
    try:
        # pipã‚’ä½¿ã£ã¦google-generativeaiãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æœ€æ–°ç‰ˆã«å¼·åˆ¶çš„ã«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", "--upgrade", "google-generativeai"
        ])
        # æ›´æ–°ãŒå®Œäº†ã—ãŸã“ã¨ã‚’ãƒˆãƒ¼ã‚¹ãƒˆé€šçŸ¥ã§çŸ¥ã‚‰ã›ã‚‹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        st.toast("âœ… Geminiãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æœ€æ–°ç‰ˆã«æ›´æ–°ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        # ã‚‚ã—å¤±æ•—ã—ãŸå ´åˆã¯ã€ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤ºã—ã¦ã‚¢ãƒ—ãƒªã‚’åœæ­¢
        st.error(f"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å¼·åˆ¶ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()
# ====================================================================
#  å¯¾ç­–ã‚³ãƒ¼ãƒ‰ã“ã“ã¾ã§
# ====================================================================

## ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import google.generativeai as genai
import json
from io import StringIO
from janome.tokenizer import Tokenizer


# --- 0. Gemini APIã‚­ãƒ¼ã®è¨­å®š ---
# Streamlitã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†æ©Ÿèƒ½ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
try:
    ## ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼èª­ã¿è¾¼ã¿
    gemini_api_key = os.environ["GEMINI_API_B2BAPP"]

    if gemini_api_key:
        genai.configure(api_key = gemini_api_key)
        ## st.success("OK:API kye")
    else:
        st.error("APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop("APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ã®ãŸã‚å‡¦ç†ã‚’åœæ­¢ã—ã¾ã™ã€‚")
except Exception as e:
    st.error(f"APIã‚­ãƒ¼è¨­å®šã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:{e}")
    exit()

# --- 1. Janomeã®åˆæœŸåŒ– ---
try:
    janome_tokenizer = Tokenizer()
except Exception as e:
    st.error(f"Janomeã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()


# --- 2. Big5æ€§æ ¼åˆ†æ + ACNç‹¬è‡ªæ€§æ ¼ã®ãƒ­ã‚¸ãƒƒã‚¯ ---
PERSONALITY_WORDS = {
    ## Big5
    'å¤–å‘æ€§': ['ã¿ã‚“ãª', 'æ¥½ã—ã„', 'ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼', 'ä¼šã†', 'è©±ã™', 'æœ€é«˜', 'ï¼', 'ï¼ˆç¬‘ï¼‰'],
    'å”èª¿æ€§': ['å”åŠ›', 'ä¸€ç·’', 'æ‰‹ä¼ã†', 'ã‚ã‚ŠãŒã¨ã†', 'ãŠé¡˜ã„ã—ã¾ã™', 'æ„Ÿè¬', 'ç§ãŸã¡'],
    'èª å®Ÿæ€§': ['è¨ˆç”»', 'ç¢ºå®Ÿ', 'ã¹ã', 'é‡è¦', 'è²¬ä»»', 'ã—ã£ã‹ã‚Š', 'ç®¡ç†', 'å ±å‘Š'],
    'ç¥çµŒç—‡å‚¾å‘': ['å¿ƒé…', 'ä¸å®‰', 'å•é¡Œ', 'é›£ã—ã„', 'å¤§å¤‰', 'ãƒªã‚¹ã‚¯', 'ã™ã¿ã¾ã›ã‚“'],
    'é–‹æ”¾æ€§': ['æ–°ã—ã„', 'ã‚¢ã‚¤ãƒ‡ã‚¢', 'é¢ç™½ã„', 'è©¦ã™', 'æƒ³åƒ', 'ã‚ãã‚ã', 'ï¼Ÿ', 'ãªã‚‹ã»ã©'],
    ## ACNã‚ªãƒªã‚¸ãƒŠãƒ«
    'çŸ­æ°—': ['ã¾ã ', 'é…ã„', 'ãŠãã„', 'ã„ãã’', 'æ€¥ã’', 'ã„ãã', 'æ€¥ã', 'ã‚„ã°', 'æ—©ã'],
    'ãƒ‘ãƒ¯ãƒãƒ©': ['ãŠã„ãŠã„', 'ã¾ã˜ã‹ã‚ˆ', 'ã‚„ã‚Œ', 'ãµã–ã‘ã‚‹ãª']
}

## ãƒãƒ£ãƒƒãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’Janomeã§å˜èªã«åˆ‡ã‚Šåˆ†ã‘
def analyze_personality(text):
    if not isinstance(text, str) or not text.strip():
        return {p: 0 for p in PERSONALITY_WORDS.keys()}
    # â†“ Janomeã®å‡¦ç†ã«ç½®ãæ›ãˆ
    words = [token.surface for token in janome_tokenizer.tokenize(text)]
    scores = {p: 0 for p in PERSONALITY_WORDS.keys()}
    for personality, keywords in PERSONALITY_WORDS.items():
        for word in keywords:
            scores[personality] += words.count(word)
    return scores

## æ–‡ç« ä¸­ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—æ€§æ ¼ã‚¿ã‚¤ãƒ—ã”ã¨ã®ã‚¹ã‚³ã‚¢ç®—å‡º
def get_dominant_personality(scores):
    if not scores or sum(scores.values()) == 0:
        return "åˆ†æä¸èƒ½"
    return max(scores, key=scores.get)

## æ€§æ ¼ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
def calculate_cosine_similarity(vec1, vec2):
    vec1 = np.array(vec1)
    vec2 = np.array(vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    if norm1 == 0 or norm2 == 0:
        return 0.0
    dot_product = np.dot(vec1, vec2)
    similarity = dot_product / (norm1 * norm2)
    return similarity

## æ€§æ ¼ã‚¹ã‚³ã‚¢ã‚’å…ƒã«ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ç”Ÿæˆ
def create_multi_user_radar_chart(result_df, my_name):
    labels = list(PERSONALITY_WORDS.keys())
    fig = go.Figure()

    # è‡ªåˆ†ä»¥å¤–ã®ãƒ¡ãƒ³ãƒãƒ¼ã«ä½¿ç”¨ã™ã‚‹è‰²ã®ãƒªã‚¹ãƒˆã‚’å®šç¾©
    other_colors = [
        '#1f77b4',  # é’
        '#2ca02c',  # ç·‘
        '#9467bd',  # ç´«
        '#ff7f0e',  # ã‚ªãƒ¬ãƒ³ã‚¸
        '#8c564b',  # èŒ¶è‰²
        '#e377c2',  # ãƒ”ãƒ³ã‚¯
        '#7f7f7f',  # ã‚°ãƒ¬ãƒ¼
        '#bcbd22',  # ã‚ªãƒªãƒ¼ãƒ–
        '#17becf'   # ã‚·ã‚¢ãƒ³
    ]
    color_index = 0

    score_details_df = result_df['ã‚¹ã‚³ã‚¢è©³ç´°'].apply(pd.Series)
    max_score = score_details_df.max().max() if not score_details_df.empty else 1

    for index, row in result_df.iterrows():
        user_name = row['ãƒ¦ãƒ¼ã‚¶ãƒ¼']
        scores = row['ã‚¹ã‚³ã‚¢è©³ç´°']
        values = list(scores.values())

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã«å¿œã˜ã¦è‰²ã‚’æ±ºå®š
        if user_name == my_name:
            line_color = 'red'
        else:
            line_color = other_colors[color_index % len(other_colors)]
            color_index += 1
        
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=labels,
            fill='toself',
            name=user_name,
            # line=dict(color=...) ã§ç·šã®è‰²ã‚’æŒ‡å®š
            line=dict(color=line_color),
            hovertemplate=f'<b>{user_name}</b><br>%{{theta}}: %{{r}}<extra></extra>'
        ))

    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, max_score if max_score > 0 else 1]
            )),
        showlegend=True,
        title="å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ€§æ ¼ã‚¹ã‚³ã‚¢æ¯”è¼ƒ"
    )
    return fig

# --- 3. Gemini APIã‚’ç”¨ã„ãŸé–¢æ•°ç¾¤ ---
def generate_persona_with_retry(target_user_name, target_user_scores, target_user_text, my_scores, max_retries=3):
    """
    Gemini APIã‚’å‘¼ã³å‡ºã—ã¦ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    """
    model = genai.GenerativeModel('gemini-2.5-flash-lite')
    default_response = {
        "persona": "AIã«ã‚ˆã‚‹äººæŸ„ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
        "common_point": "å…±é€šç‚¹ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
        "communication_point": "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒã‚¤ãƒ³ãƒˆã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    }
    prompt = f"""
    ã‚ãªãŸã¯ã€å„ªç§€ãªçµ„ç¹”äººäº‹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€{target_user_name}ã•ã‚“ã®ãƒšãƒ«ã‚½ãƒŠã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
    # åˆ†æå¯¾è±¡è€…ã®æƒ…å ±
    - æ°å: {target_user_name}
    - æ€§æ ¼ã‚¹ã‚³ã‚¢: {target_user_scores}
    - ãƒãƒ£ãƒƒãƒˆç™ºè¨€ã®æŠœç²‹: {target_user_text[:200]}
    # æ¯”è¼ƒå¯¾è±¡è€…ï¼ˆè‡ªåˆ†ï¼‰ã®æƒ…å ±
    - æ€§æ ¼ã‚¹ã‚³ã‚¢: {my_scores}
    #ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
    - **å¿…ãšã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ"ã ã‘"ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚**
    - **è§£èª¬ã‚„å‰ç½®ãã€```jsonã®ã‚ˆã†ãªè¿½åŠ ã®æ–‡å­—åˆ—ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚**
    {{
    "persona": "ï¼ˆ{target_user_name}ã•ã‚“ã®äººæŸ„ã‚’50æ–‡å­—ç¨‹åº¦ã§èª¬æ˜ï¼‰",
    "common_point": "ï¼ˆè‡ªåˆ†ã¨ã®æ€§æ ¼ã‚¹ã‚³ã‚¢ã®å…±é€šç‚¹ã‚’30æ–‡å­—ç¨‹åº¦ã§èª¬æ˜ï¼‰",
    "communication_point": "ï¼ˆå††æ»‘ãªé–¢ä¿‚ã‚’ç¯‰ããŸã‚ã®ãƒã‚¤ãƒ³ãƒˆã‚’50æ–‡å­—ç¨‹åº¦ã§èª¬æ˜ï¼‰"
    }}
    """
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            cleaned_text = response.text.strip().replace("```json", "").replace("```", "").strip()
            persona_data = json.loads(cleaned_text)
            if all(k in persona_data for k in ["persona", "common_point", "communication_point"]):
                return persona_data
        except (json.JSONDecodeError, Exception) as e:
            st.error(f"AIã‹ã‚‰ã®å¿œç­”å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆè©¦è¡Œ {attempt + 1}å›ç›®ï¼‰: {e}")
            if 'response' in locals() and hasattr(response, 'text'):
                st.text_area("AIã‹ã‚‰ã®ç”Ÿã®å¿œç­”:", response.text, height=150)
            if attempt == max_retries - 1:
                return default_response
    return default_response

def generate_team_atmosphere(text, max_retries=3):
    """
    MTGã®ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒ¼ãƒ ã®é›°å›²æ°—ã‚’åˆ†æã™ã‚‹é–¢æ•°
    """
    model = genai.GenerativeModel('gemini-2.5-flash-lite')
    default_response = {"atmosphere": "åˆ†æå¤±æ•—", "description": "AIã«ã‚ˆã‚‹åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "weather": "éœ§"}
    weather_options = ['å¿«æ™´', 'æ™´ã‚Œ', 'è–„æ›‡ã‚Š', 'æ›‡ã‚Š', 'é›¨', 'é›ª', 'é›·', 'éœ§', 'æš´é¢¨']
    prompt = f"""
    ã‚ãªãŸã¯ã€çµŒé¨“è±Šå¯Œãªçµ„ç¹”é–‹ç™ºã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‹ã‚‰ã€ãƒãƒ¼ãƒ å…¨ä½“ã®é›°å›²æ°—ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
    # åˆ†æå¯¾è±¡ã®ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæŠœç²‹ï¼‰
    {text[:4000]}
    #ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
    - **å¿…ãšã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ"ã ã‘"ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚**
    - **è§£èª¬ã‚„å‰ç½®ãã€```jsonã®ã‚ˆã†ãªè¿½åŠ ã®æ–‡å­—åˆ—ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚**
    - **"weather"ã®å€¤ã¯ã€å¿…ãšä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã‹ã‚‰æœ€ã‚‚é©åˆ‡ã ã¨æ€ã†ã‚‚ã®ã‚’1ã¤ã ã‘é¸ã‚“ã§ãã ã•ã„ã€‚**
      {weather_options}
    {{
      "atmosphere": "ï¼ˆãƒãƒ¼ãƒ ã®é›°å›²æ°—ã‚’15æ–‡å­—ç¨‹åº¦ã§è¡¨ç¾ï¼‰",
      "description": "ï¼ˆãªãœãã®é›°å›²æ°—ã ã¨åˆ¤æ–­ã—ãŸã‹ã€ç†ç”±ã‚’30æ–‡å­—ç¨‹åº¦ã§èª¬æ˜ï¼‰",
      "weather": "ï¼ˆä¸Šè¨˜ã®ãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠã—ãŸå¤©æ°—ï¼‰"
    }}
    """
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            cleaned_text = response.text.strip().replace("```json", "").replace("```", "").strip()
            atmosphere_data = json.loads(cleaned_text)
            if all(k in atmosphere_data for k in ["atmosphere", "description", "weather"]):
                return atmosphere_data
        except (json.JSONDecodeError, Exception) as e:
            st.error(f"ãƒãƒ¼ãƒ é›°å›²æ°—ã®AIåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆè©¦è¡Œ {attempt + 1}å›ç›®ï¼‰: {e}")
            if attempt == max_retries - 1:
                return default_response
    return default_response

def get_weather_icon(weather_str):
    """ å¤©æ°—ã®æ–‡å­—åˆ—ã«å¯¾å¿œã™ã‚‹çµµæ–‡å­—ã‚’è¿”ã™ """
    weather_map = {
        'å¿«æ™´': 'â˜€ï¸', 'æ™´ã‚Œ': 'æ™´ï¸', 'è–„æ›‡ã‚Š': 'ğŸŒ¥ï¸', 'æ›‡ã‚Š': 'â˜ï¸', 'é›¨': 'ğŸŒ§ï¸',
        'é›ª': 'â„ï¸', 'é›·': 'âš¡ï¸', 'éœ§': 'ğŸŒ«ï¸', 'æš´é¢¨': 'ğŸŒªï¸'
    }
    return weather_map.get(weather_str, 'â“')

##ã“ã“ã‹ã‚‰ä¿®æ­£
# --- 3-3. Gemini APIã‚’ç”¨ã„ãŸç·åˆè©•ä¾¡é–¢æ•° ---
def generate_overall_evaluation(atmosphere_result, result_df, my_name, max_retries=3):
    """
    å…¨ã¦ã®åˆ†æçµæœã‚’çµ±åˆã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å‚åŠ æ¨å¥¨åº¦ã‚’è©•ä¾¡ã™ã‚‹é–¢æ•°
    """
    model = genai.GenerativeModel('gemini-2.5-flash-lite')
    
    # AIã«æ¸¡ã™ãŸã‚ã«ã€ã“ã‚Œã¾ã§ã®åˆ†æçµæœã‚’è¦ç´„ã—ã¾ã™
    team_atmosphere = atmosphere_result.get('atmosphere', 'ä¸æ˜')
    team_weather = atmosphere_result.get('weather', 'ä¸æ˜')
    
    my_data = result_df[result_df['ãƒ¦ãƒ¼ã‚¶ãƒ¼'] == my_name]
    my_dominant_personality = my_data['æœ€ã‚‚å¼·ã„æ€§æ ¼å‚¾å‘'].iloc[0] if not my_data.empty else 'ä¸æ˜'
    
    other_members_data = result_df[result_df['ãƒ¦ãƒ¼ã‚¶ãƒ¼'] != my_name]
    # `mean()`ã§å¹³å‡å€¤ã‚’è¨ˆç®—ã€‚ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯0ã¨ã—ã¾ã™ã€‚
    average_match_score = other_members_data['è‡ªåˆ†ã¨ã®æ€§æ ¼ãƒãƒƒãƒåº¦ (%)'].mean() if not other_members_data.empty else 0
    # `value_counts()`ã§æ€§æ ¼ã‚¿ã‚¤ãƒ—ã®äººæ•°ã‚’æ•°ãˆã€`to_dict()`ã§è¾æ›¸ã«å¤‰æ›ã—ã¾ã™
    team_composition = other_members_data['æœ€ã‚‚å¼·ã„æ€§æ ¼å‚¾å‘'].value_counts().to_dict()

    # è§£æå¤±æ•—æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¿œç­”
    default_response = {
        "recommendation": "è‡ªå·±åˆ¤æ–­ã«å§”ã­ã‚‹",
        "reason": "AIã«ã‚ˆã‚‹ç·åˆè©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    }

    # AIã«é¸ã°ã›ã‚‹é¸æŠè‚¢ã‚’å®šç¾©
    recommendation_options = ["å¼·ãæ¨å¥¨ã™ã‚‹", "æ¨å¥¨ã™ã‚‹", "è‡ªå·±åˆ¤æ–­ã«å§”ã­ã‚‹", "æ¨å¥¨ã—ãªã„"]

    prompt = f"""
    ã‚ãªãŸã¯ã€è¶…ä¸€æµã®çµ„ç¹”äººäº‹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆå…¼ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
    ä»¥ä¸‹ã®å¤šè§’çš„ãªåˆ†æçµæœã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆ{my_name}ã•ã‚“ï¼‰ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å‚åŠ ã™ã¹ãã‹ã©ã†ã‹ã€ç·åˆçš„ãªè©•ä¾¡ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚

    # åˆ†æãƒ‡ãƒ¼ã‚¿
    1. **ãƒãƒ¼ãƒ å…¨ä½“ã®é›°å›²æ°—**:
       - é›°å›²æ°—: {team_atmosphere} (å¤©æ°—ã§è¨€ã†ã¨ã€Œ{team_weather}ã€)

    2. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã®æ€§æ ¼åˆ†æ**:
       - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€ã‚‚å¼·ã„æ€§æ ¼å‚¾å‘: {my_dominant_personality}
       - ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã¨ã®å¹³å‡æ€§æ ¼ãƒãƒƒãƒåº¦: {average_match_score:.1f}%
       - ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã®æ€§æ ¼å‚¾å‘ã®å†…è¨³: {team_composition}

    #ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
    - **å¿…ãšã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ"ã ã‘"ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚**
    - **è§£èª¬ã‚„å‰ç½®ãã€```jsonã®ã‚ˆã†ãªè¿½åŠ ã®æ–‡å­—åˆ—ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚**
    - **"recommendation"ã®å€¤ã¯ã€å¿…ãšä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã‹ã‚‰æœ€ã‚‚é©åˆ‡ã ã¨æ€ã†ã‚‚ã®ã‚’1ã¤ã ã‘é¸ã‚“ã§ãã ã•ã„ã€‚**
      {recommendation_options}
    - **"reason"ã¯ã€ãã®çµè«–ã«è‡³ã£ãŸæ ¹æ‹ ã‚’20æ–‡å­—ç¨‹åº¦ã§ç°¡æ½”ã«è¿°ã¹ã¦ãã ã•ã„ã€‚**

    {{
      "recommendation": "ï¼ˆä¸Šè¨˜ã®ãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠï¼‰",
      "reason": "ï¼ˆè©•ä¾¡ç†ç”±ã‚’20æ–‡å­—ç¨‹åº¦ã§èª¬æ˜ï¼‰"
    }}
    """
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            cleaned_text = response.text.strip().replace("```json", "").replace("```", "").strip()
            evaluation_data = json.loads(cleaned_text)
            
            if all(k in evaluation_data for k in ["recommendation", "reason"]):
                return evaluation_data # æˆåŠŸ
        except (json.JSONDecodeError, Exception) as e:
            st.error(f"ç·åˆè©•ä¾¡ã®AIåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆè©¦è¡Œ {attempt + 1}å›ç›®ï¼‰: {e}")
            if attempt == max_retries - 1:
                return default_response
    
    return default_response

def get_recommendation_color(recommendation_str):
    """ æ¨å¥¨åº¦ã«å¿œã˜ã¦è‰²ã‚’è¿”ã™ """
    if recommendation_str == "å¼·ãæ¨å¥¨ã™ã‚‹":
        return "green"
    elif recommendation_str == "æ¨å¥¨ã™ã‚‹":
        return "blue"
    elif recommendation_str == "æ¨å¥¨ã—ãªã„":
        return "red"
    else: # è‡ªå·±åˆ¤æ–­ã«å§”ã­ã‚‹
        return "orange"
##ä¿®æ­£ã“ã“ã¾ã§

# --- 4. Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”»é¢ ---
st.title('ã‚¢ã‚µã‚¤ãƒ³æ¤œè¨PJ æ€§æ ¼åˆ†æã‚¢ãƒ—ãƒª ğŸ’¬')
st.write('ã‚¢ã‚µã‚¤ãƒ³äºˆå®šã®PJãƒ¡ãƒ³ãƒãƒ¼ã®ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã€MTGä¼šè©±ãƒ‡ãƒ¼ã‚¿ã¨ã‚ãªãŸã®ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿(CSV)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€ãƒãƒ¼ãƒ ã®é›°å›²æ°—ã‚„ãƒ¡ãƒ³ãƒãƒ¼ã®æ€§æ ¼å‚¾å‘ã‚’åˆ†æã—ã€PJã¨ã‚ãªãŸã®ãƒãƒƒãƒãƒ³ã‚°ã‚’è¨ºæ–­ã—ã¾ã™ã€‚')
st.write('---')

col1, col2, col3 = st.columns(3)
with col1:
    st.subheader("ğŸ‘¥PJãƒ¡ãƒ³ãƒãƒ¼ã®Teamsãƒãƒ£ãƒƒãƒˆ")
    chat_files = st.file_uploader("PJã®ãƒãƒ£ãƒƒãƒˆCSVã‚’é¸æŠ", type="csv", accept_multiple_files=True, key="chat_uploader")
with col2:
    st.subheader("ğŸ‘¥PJãƒ¡ãƒ³ãƒãƒ¼ã®MTGä¼šè©±")
    transcript_files = st.file_uploader("éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã—ãŸCSVã‚’é¸æŠ", type="csv", accept_multiple_files=True, key="transcript_uploader")
with col3:
    st.subheader("ğŸ‘¤è‡ªåˆ†ã®Teamsãƒãƒ£ãƒƒãƒˆ")
    my_file = st.file_uploader("è‡ªåˆ†ã®ãƒãƒ£ãƒƒãƒˆã®CSVã‚’é¸æŠ", type="csv", accept_multiple_files=False, key="mychat_uploader")
st.write('---')

if (chat_files or transcript_files) and my_file:
    try:
        # --- ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿å‡¦ç† ---
        team_chat_dfs = []
        if chat_files:
            for file in chat_files:
                file.seek(0)
                try: df_single = pd.read_csv(file, encoding='shift_jis')
                except UnicodeDecodeError:
                    file.seek(0)
                    df_single = pd.read_csv(file, encoding='utf-8')
                team_chat_dfs.append(df_single)
        team_chat_df = pd.concat(team_chat_dfs, ignore_index=True) if team_chat_dfs else pd.DataFrame()

        transcript_text = ""
        if transcript_files:
            team_transcript_dfs = []
            for file in transcript_files:
                file.seek(0)
                try: df_single = pd.read_csv(file, encoding='shift_jis')
                except UnicodeDecodeError:
                    file.seek(0)
                    df_single = pd.read_csv(file, encoding='utf-8')
                team_transcript_dfs.append(df_single)
            if team_transcript_dfs:
                team_transcript_df = pd.concat(team_transcript_dfs, ignore_index=True)
                if 'message' in team_transcript_df.columns:
                    transcript_text = ' '.join(team_transcript_df['message'].fillna('').astype(str))

        try:
            my_file.seek(0)
            my_df = pd.read_csv(my_file, encoding='shift_jis')
        except UnicodeDecodeError:
            my_file.seek(0)
            my_df = pd.read_csv(my_file, encoding='utf-8')

        if 'user' in my_df.columns and not my_df.empty:
            my_name = my_df['user'].iloc[0]
            st.info(f"ã‚ãªãŸã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’ã€Œ{my_name}ã€ã¨ã—ã¦èªè­˜ã—ã¾ã—ãŸã€‚")
        else:
            st.error("ã‚ãªãŸã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã« 'user' åˆ—ãŒå­˜åœ¨ã—ãªã„ã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚"); st.stop()
        
        df = pd.concat([team_chat_df, my_df], ignore_index=True)
        st.success(f'{len(chat_files) + len(transcript_files) + 1}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸï¼')

        if st.button('åˆ†æã‚’å®Ÿè¡Œã™ã‚‹'):
            st.write('---'); st.header('åˆ†æçµæœ')
            atmosphere_result, result_df = None, pd.DataFrame() # çµæœã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°ã‚’åˆæœŸåŒ–

            # --- ãƒãƒ¼ãƒ ã®é›°å›²æ°—åˆ†æ ---
            if transcript_text:
                st.subheader('ğŸ—£ï¸ PJãƒãƒ¼ãƒ ã®é›°å›²æ°—')
                with st.spinner('AIãŒãƒãƒ¼ãƒ ã®é›°å›²æ°—ã‚’åˆ†æä¸­ã§ã™...'):
                    atmosphere_result = generate_team_atmosphere(transcript_text)
                    weather_str = atmosphere_result.get('weather', 'éœ§')
                    col_atm1, col_atm2, col_atm3 = st.columns(3)
                    col_atm1.metric("ç¾åœ¨ã®ãƒãƒ¼ãƒ ã®å¤©æ°—", weather_str, get_weather_icon(weather_str))
                    col_atm2.info(f"**é›°å›²æ°—**: {atmosphere_result.get('atmosphere', 'N/A')}")
                    col_atm3.success(f"**ç†ç”±**: {atmosphere_result.get('description', 'N/A')}")
                st.write('---')
            
            # --- æ€§æ ¼ãƒãƒƒãƒåº¦åˆ†æ ---
            if not df.empty and 'user' in df.columns and df['user'].nunique() > 1:
                df['message'] = df['message'].fillna('')
                user_texts = df.groupby('user')['message'].agg(' '.join).reset_index()
                results = []
                with st.spinner('æ€§æ ¼ã‚¹ã‚³ã‚¢ã‚’åˆ†æä¸­ã§ã™...'):
                    for _, row in user_texts.iterrows():
                        scores = analyze_personality(row['message'])
                        results.append({
                            'ãƒ¦ãƒ¼ã‚¶ãƒ¼': row['user'], 'æœ€ã‚‚å¼·ã„æ€§æ ¼å‚¾å‘': get_dominant_personality(scores),
                            'ç™ºè¨€æ•°': df[df['user'] == row['user']].shape[0],
                            'ã‚¹ã‚³ã‚¢è©³ç´°': scores, 'å…¨ç™ºè¨€': row['message']
                        })
                result_df = pd.DataFrame(results)
                if my_name in result_df['ãƒ¦ãƒ¼ã‚¶ãƒ¼'].values:
                    my_scores_row = result_df[result_df['ãƒ¦ãƒ¼ã‚¶ãƒ¼'] == my_name].iloc[0]
                    my_scores = my_scores_row['ã‚¹ã‚³ã‚¢è©³ç´°']
                    my_scores_list = list(my_scores.values())
                    match_percentages = [
                        round(calculate_cosine_similarity(my_scores_list, list(row['ã‚¹ã‚³ã‚¢è©³ç´°'].values())) * 100, 2)
                        if row['ãƒ¦ãƒ¼ã‚¶ãƒ¼'] != my_name else 100.0
                        for _, row in result_df.iterrows()
                    ]
                    result_df['è‡ªåˆ†ã¨ã®æ€§æ ¼ãƒãƒƒãƒåº¦ (%)'] = match_percentages
                    st.subheader(f'ğŸ‘¤ {my_name} ã¨PJãƒ¡ãƒ³ãƒãƒ¼ã®æ€§æ ¼ãƒãƒƒãƒåº¦')
                    st.dataframe(result_df[['ãƒ¦ãƒ¼ã‚¶ãƒ¼', 'æœ€ã‚‚å¼·ã„æ€§æ ¼å‚¾å‘', 'ç™ºè¨€æ•°', 'è‡ªåˆ†ã¨ã®æ€§æ ¼ãƒãƒƒãƒåº¦ (%)']].sort_values('è‡ªåˆ†ã¨ã®æ€§æ ¼ãƒãƒƒãƒåº¦ (%)', ascending=False))
                    st.write('---')
                    st.subheader('ğŸ“ˆ è‡ªåˆ†ã¨PJãƒ¡ãƒ³ãƒãƒ¼ã®æ€§æ ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ')
                    st.plotly_chart(create_multi_user_radar_chart(result_df, my_name), use_container_width=True)
                    st.write('---')
                    st.subheader('ğŸ¤– PJãƒ¡ãƒ³ãƒãƒ¼ã®ãƒšãƒ«ã‚½ãƒŠåˆ†æ')
                    other_users_df = result_df[result_df['ãƒ¦ãƒ¼ã‚¶ãƒ¼'] != my_name].sort_values('è‡ªåˆ†ã¨ã®æ€§æ ¼ãƒãƒƒãƒåº¦ (%)', ascending=False)
                    with st.spinner('AIãŒå„ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆä¸­ã§ã™...'):
                        user_list = list(other_users_df.iterrows())
                        for i in range(0, len(user_list), 2):
                            col1, col2 = st.columns(2)
                            # 1äººç›®
                            _, row1 = user_list[i]
                            with col1.expander(f"**{row1['ãƒ¦ãƒ¼ã‚¶ãƒ¼']}ã•ã‚“** ã®ãƒšãƒ«ã‚½ãƒŠã‚’è¦‹ã‚‹", expanded=True):
                                persona = generate_persona_with_retry(row1['ãƒ¦ãƒ¼ã‚¶ãƒ¼'], row1['ã‚¹ã‚³ã‚¢è©³ç´°'], row1['å…¨ç™ºè¨€'], my_scores)
                                st.info(f"**äººæŸ„**: {persona.get('persona', 'N/A')}")
                                st.success(f"**å…±é€šç‚¹**: {persona.get('common_point', 'N/A')}")
                                st.warning(f"**ãƒã‚¤ãƒ³ãƒˆ**: {persona.get('communication_point', 'N/A')}")
                            # 2äººç›® (å­˜åœ¨ã™ã‚Œã°)
                            if (i + 1) < len(user_list):
                                _, row2 = user_list[i + 1]
                                with col2.expander(f"**{row2['ãƒ¦ãƒ¼ã‚¶ãƒ¼']}ã•ã‚“** ã®ãƒšãƒ«ã‚½ãƒŠã‚’è¦‹ã‚‹", expanded=True):
                                    persona = generate_persona_with_retry(row2['ãƒ¦ãƒ¼ã‚¶ãƒ¼'], row2['ã‚¹ã‚³ã‚¢è©³ç´°'], row2['å…¨ç™ºè¨€'], my_scores)
                                    st.info(f"**äººæŸ„**: {persona.get('persona', 'N/A')}")
                                    st.success(f"**å…±é€šç‚¹**: {persona.get('common_point', 'N/A')}")
                                    st.warning(f"**ãƒã‚¤ãƒ³ãƒˆ**: {persona.get('communication_point', 'N/A')}")
            else:
                 st.info("æ€§æ ¼åˆ†æã‚’è¡Œã†ã«ã¯ã€PJãƒ¡ãƒ³ãƒãƒ¼ã®ãƒãƒ£ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨è‡ªåˆ†ã®ãƒãƒ£ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¡æ–¹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

            ##ã“ã“ã‹ã‚‰ä¿®æ­£
            # --- ç·åˆè©•ä¾¡ ---
            st.write('---')
            st.header('ğŸ“Š ç·åˆè©•ä¾¡')

            # é›°å›²æ°—åˆ†æã¨æ€§æ ¼åˆ†æã®ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
            if atmosphere_result and not result_df.empty:
                with st.spinner('AIãŒã™ã¹ã¦ã®çµæœã‚’çµ±åˆã—ã€æœ€çµ‚è©•ä¾¡ã‚’ç”Ÿæˆä¸­ã§ã™...'):
                    evaluation = generate_overall_evaluation(atmosphere_result, result_df, my_name)
                    recommendation = evaluation.get('recommendation', 'è©•ä¾¡ä¸èƒ½')
                    reason = evaluation.get('reason', 'ç†ç”±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚')
                    color = get_recommendation_color(recommendation)
                    
                    st.markdown(f"### ã‚ãªãŸã¸ã®æ¨å¥¨åº¦: <font color='{color}'>**{recommendation}**</font>", unsafe_allow_html=True)
                    st.info(f"**ç†ç”±**: {reason}")
            else:
                st.warning("ç·åˆè©•ä¾¡ã‚’è¡Œã†ã«ã¯ã€PJãƒ¡ãƒ³ãƒãƒ¼ã®ã€ŒMTGä¼šè©±ã€ã¨ã€ŒTeamsãƒãƒ£ãƒƒãƒˆã€ã®ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æã‚’å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
            ##ä¿®æ­£ã“ã“ã¾ã§

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")