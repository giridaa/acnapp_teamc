# app.py

import streamlit as st
import pandas as pd
import MeCab
import numpy as np
import plotly.graph_objects as go
from io import StringIO

# --- 1. MeCabã®åˆæœŸåŒ– (Google Colabå‘ã‘) ---
try:
    mecab = MeCab.Tagger("-Owakati")
except Exception as e:
    st.error(f"MeCabã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")
    st.info("Google Colabç’°å¢ƒã§ã¯ã€!pip install mecab-python3 unidic-lite ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    st.stop()


# --- 2. Big5æ€§æ ¼åˆ†æã®ãƒ­ã‚¸ãƒƒã‚¯ ---
PERSONALITY_WORDS = {
    'å¤–å‘æ€§': ['ã¿ã‚“ãª', 'æ¥½ã—ã„', 'ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼', 'ä¼šã†', 'è©±ã™', 'æœ€é«˜', 'ï¼', 'ï¼ˆç¬‘ï¼‰'],
    'å”èª¿æ€§': ['å”åŠ›', 'ä¸€ç·’', 'æ‰‹ä¼ã†', 'ã‚ã‚ŠãŒã¨ã†', 'ãŠé¡˜ã„ã—ã¾ã™', 'æ„Ÿè¬', 'ç§ãŸã¡'],
    'èª å®Ÿæ€§': ['è¨ˆç”»', 'ç¢ºå®Ÿ', 'ã¹ã', 'é‡è¦', 'è²¬ä»»', 'ã—ã£ã‹ã‚Š', 'ç®¡ç†', 'å ±å‘Š'],
    'ç¥çµŒç—‡å‚¾å‘': ['å¿ƒé…', 'ä¸å®‰', 'å•é¡Œ', 'é›£ã—ã„', 'å¤§å¤‰', 'ãƒªã‚¹ã‚¯', 'ã™ã¿ã¾ã›ã‚“'],
    'é–‹æ”¾æ€§': ['æ–°ã—ã„', 'ã‚¢ã‚¤ãƒ‡ã‚¢', 'é¢ç™½ã„', 'è©¦ã™', 'æƒ³åƒ', 'ã‚ãã‚ã', 'ï¼Ÿ', 'ãªã‚‹ã»ã©']
}

def analyze_personality(text):
    if not isinstance(text, str) or not text.strip():
        return {p: 0 for p in PERSONALITY_WORDS.keys()}
    words = mecab.parse(text).split()
    scores = {p: 0 for p in PERSONALITY_WORDS.keys()}
    for personality, keywords in PERSONALITY_WORDS.items():
        for word in keywords:
            scores[personality] += words.count(word)
    return scores

def get_dominant_personality(scores):
    if not scores or sum(scores.values()) == 0:
        return "åˆ†æä¸èƒ½"
    return max(scores, key=scores.get)

def calculate_cosine_similarity(vec1, vec2):
    vec1 = np.array(vec1)
    vec2 = np.array(vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    if norm1 == 0 or norm2 == 0:
        return 0.0
    dot_product = np.dot(vec1, vec2)
    similarity = dot_product / (norm1 * norm2)
    return similarity

def create_multi_user_radar_chart(result_df):
    labels = list(PERSONALITY_WORDS.keys())
    fig = go.Figure()
    score_details_df = result_df['ã‚¹ã‚³ã‚¢è©³ç´°'].apply(pd.Series)
    max_score = score_details_df.max().max()
    for index, row in result_df.iterrows():
        user_name = row['ãƒ¦ãƒ¼ã‚¶ãƒ¼']
        scores = row['ã‚¹ã‚³ã‚¢è©³ç´°']
        values = list(scores.values())
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=labels,
            fill='toself',
            name=user_name,
            hovertemplate=f'<b>{user_name}</b><br>%{{theta}}: %{{r}}<extra></extra>'
        ))
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, max_score if max_score > 0 else 1]
            )),
        showlegend=True,
        title="å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ€§æ ¼ã‚¹ã‚³ã‚¢æ¯”è¼ƒ"
    )
    return fig


# --- 3. Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”»é¢ ---
st.title('Teamsãƒãƒ£ãƒƒãƒˆ æ€§æ ¼åˆ†æã‚¢ãƒ—ãƒª ğŸ’¬')
st.write('ã‚¢ã‚µã‚¤ãƒ³äºˆå®šã®PJãƒ¡ãƒ³ãƒãƒ¼ã¨ã‚ãªãŸã®ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿(CSV)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€æ€§æ ¼å‚¾å‘ã‚’åˆ†æã—ã€PJãƒ¡ãƒ³ãƒãƒ¼ã¨ã®ã€Œæ€§æ ¼ãƒãƒƒãƒåº¦ã€ã‚’è¨ºæ–­ã—ã¾ã™ã€‚')
st.write('---')

# 2ã¤ã®ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
col1, col2 = st.columns(2)

# å·¦å´ã®ã‚«ãƒ©ãƒ ã«ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ç”¨ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’é…ç½®
with col1:
    st.subheader("PJãƒ¡ãƒ³ãƒãƒ¼ã®ãƒãƒ£ãƒƒãƒˆ")
    team_files = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¤‡æ•°é¸æŠã—ã¦ãã ã•ã„",
        type="csv",
        accept_multiple_files=True,
        key="team_uploader"
    )

# å³å´ã®ã‚«ãƒ©ãƒ ã«è‡ªåˆ†ç”¨ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’é…ç½®
with col2:
    st.subheader("è‡ªåˆ†ã®ãƒãƒ£ãƒƒãƒˆ")
    my_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤é¸æŠã—ã¦ãã ã•ã„",
        type="csv",
        accept_multiple_files=False,
        key="my_uploader"
    )

st.write('---')

if team_files and my_file:
    try:
        # --- ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
        team_dfs = []
        for file in team_files:
            file.seek(0)
            try:
                df_single = pd.read_csv(file, encoding='shift_jis')
            except UnicodeDecodeError:
                file.seek(0)
                df_single = pd.read_csv(file, encoding='utf-8')
            team_dfs.append(df_single)
        team_df = pd.concat(team_dfs, ignore_index=True)

        # --- ã‚ãªãŸã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
        my_file.seek(0)
        try:
            my_df = pd.read_csv(my_file, encoding='shift_jis')
        except UnicodeDecodeError:
            my_file.seek(0)
            my_df = pd.read_csv(my_file, encoding='utf-8')

        # --- ã‚ãªãŸã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å–å¾— ---
        my_name = ""
        if 'user' in my_df.columns and not my_df.empty:
            my_name = my_df['user'].iloc[0]
            st.info(f"ã‚ãªãŸã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’ã€Œ{my_name}ã€ã¨ã—ã¦èªè­˜ã—ã¾ã—ãŸã€‚")
        else:
            st.error("ã‚ãªãŸã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã« 'user' åˆ—ãŒå­˜åœ¨ã—ãªã„ã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
            st.stop()
        
        # --- å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ ---
        df = pd.concat([team_df, my_df], ignore_index=True)
        
        if 'user' not in df.columns or 'message' not in df.columns:
            st.error("ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ 'user' ã¨ 'message' ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        else:
            st.success(f'{len(team_files) + 1}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸï¼')
            
            with st.expander("èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                st.write("â–¼ ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­5è¡Œï¼‰")
                st.dataframe(team_df.head())
                st.write("â–¼ ã‚ãªãŸã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­5è¡Œï¼‰")
                st.dataframe(my_df.head())

            if st.button('PJãƒ¡ãƒ³ãƒãƒ¼ã¨ã®æ€§æ ¼ãƒãƒƒãƒãƒ³ã‚°ã‚’ç¢ºèª'):
                st.write('---')
                st.header('åˆ†æçµæœ')
                df['message'] = df['message'].fillna('')
                user_texts = df.groupby('user')['message'].apply(' '.join).reset_index()
                
                results = []
                with st.spinner('åˆ†æä¸­ã§ã™...'):
                    for index, row in user_texts.iterrows():
                        user = row['user']
                        text = row['message']
                        scores = analyze_personality(text)
                        dominant_personality = get_dominant_personality(scores)
                        results.append({
                            'ãƒ¦ãƒ¼ã‚¶ãƒ¼': user,
                            'æœ€ã‚‚å¼·ã„æ€§æ ¼å‚¾å‘': dominant_personality,
                            'ç™ºè¨€æ•°': df[df['user'] == user].shape[0],
                            'ã‚¹ã‚³ã‚¢è©³ç´°': scores
                        })
                
                result_df = pd.DataFrame(results)

                if my_name in result_df['ãƒ¦ãƒ¼ã‚¶ãƒ¼'].values:
                    my_scores_row = result_df[result_df['ãƒ¦ãƒ¼ã‚¶ãƒ¼'] == my_name].iloc[0]
                    my_scores_list = list(my_scores_row['ã‚¹ã‚³ã‚¢è©³ç´°'].values())
                    match_percentages = []
                    for index, row in result_df.iterrows():
                        if row['ãƒ¦ãƒ¼ã‚¶ãƒ¼'] == my_name:
                            match_percentages.append(100.0)
                            continue
                        other_scores_list = list(row['ã‚¹ã‚³ã‚¢è©³ç´°'].values())
                        similarity = calculate_cosine_similarity(my_scores_list, other_scores_list)
                        match_percentages.append(round(similarity * 100, 2))
                    
                    result_df['è‡ªåˆ†ã¨ã®æ€§æ ¼ãƒãƒƒãƒåº¦ (%)'] = match_percentages
                    
                    st.subheader(f'ğŸ‘¤ {my_name} ã¨PJãƒ¡ãƒ³ãƒãƒ¼ã®æ€§æ ¼ãƒãƒƒãƒåº¦')
                    st.dataframe(
                        result_df[['ãƒ¦ãƒ¼ã‚¶ãƒ¼', 'æœ€ã‚‚å¼·ã„æ€§æ ¼å‚¾å‘', 'ç™ºè¨€æ•°', 'è‡ªåˆ†ã¨ã®æ€§æ ¼ãƒãƒƒãƒåº¦ (%)']]
                        .sort_values('è‡ªåˆ†ã¨ã®æ€§æ ¼ãƒãƒƒãƒåº¦ (%)', ascending=False)
                    )
                else:
                    st.warning(f"'{my_name}'ã®ãƒ‡ãƒ¼ã‚¿ãŒåˆ†æçµæœã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.dataframe(result_df[['ãƒ¦ãƒ¼ã‚¶ãƒ¼', 'æœ€ã‚‚å¼·ã„æ€§æ ¼å‚¾å‘', 'ç™ºè¨€æ•°']])
                
                st.write('---')
                st.subheader('ğŸ“ˆ å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ€§æ ¼ã‚¹ã‚³ã‚¢æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ')
                if not result_df.empty:
                    fig = create_multi_user_radar_chart(result_df)
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.write("åˆ†æå¯¾è±¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                
                with st.expander("å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¹ã‚³ã‚¢è©³ç´°ã‚’è¦‹ã‚‹"):
                    score_details_df = result_df.set_index('ãƒ¦ãƒ¼ã‚¶ãƒ¼')['ã‚¹ã‚³ã‚¢è©³ç´°'].apply(pd.Series)
                    st.dataframe(score_details_df)

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")